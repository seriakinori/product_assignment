{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d0ac07-cda0-43ac-8ade-b933bf0f3ffa",
   "metadata": {},
   "source": [
    "# プロダクト開発試験"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba82326-ad49-447b-9205-7d5abe995904",
   "metadata": {},
   "source": [
    "## テーマ設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbbf19-be37-4632-a64b-812cb5fadc8c",
   "metadata": {},
   "source": [
    "プロダクト開発試験として、課題番号**004**の**文章をカテゴリー分類するモデルの作成**に取り組みました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba68b2f-c617-4c4c-a207-25cef0030669",
   "metadata": {},
   "source": [
    "データセットとして**ライブドアニュースコーパス**を使用し、単語分散表現・GRUとCNN、Attentionを組み合わせてより良いモデルを作成しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35c232-dfb5-479c-8659-b3b4c6635305",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fccff23a-c4bc-4b48-834d-c0037b10c03d",
   "metadata": {},
   "source": [
    "本プロダクト開発課題では、ライブドアニュースコーパスを用いた日本語文章分類の精度向上を目的としてモデルの構築を行いました。9つのカテゴリへの多クラス分類タスクに対し、2つの深層学習モデルを構築し、その性能を比較検証しました。\n",
    "\n",
    "まず、ベースラインとして、局所的な特徴抽出に優れたCNN（畳み込みニューラルネットワーク）と、時系列情報を捉えるGRUを組み合わせたモデルを実装しました。\n",
    "\n",
    "次に、改善モデルとして、Transformerの設計思想に基づき、CNNを自己注意機構（Self-Attention）に置き換え、文全体の構造的・文脈的関係性を捉えるモデルを構築しました。両モデルの実装にはPyTorchを用い、テキストの前処理にはJanomeによる形態素解析を適用しました。\n",
    "\n",
    "実験の結果、ベースラインモデルは正解率83.3%を達成しました。一方、残差接続や層正規化を取り入れた改善モデルは、正解率を89.0%まで向上させ、約5.7ポイントの大幅な性能向上を確認しました。特に、ベースラインが苦手としていた広範なテーマのカテゴリ（例: livedoor-homme, peachy）において、F1スコアの顕著な改善を確認しました（それぞれ0.50→0.65, 0.68→0.77）。\n",
    "\n",
    "以上の結果から、局所的な特徴だけでなく文全体の文脈情報を捉える自己注意機構が、本タスクにおいてCNNよりも優れた特徴抽出器として機能し、分類精度向上に有効であるという結論が得られました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82c1d4-5686-4a05-b5e5-d78878739512",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 環境構築"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a6bed-673b-44ba-a457-eb20ec4f86c4",
   "metadata": {},
   "source": [
    "### ライブラリのインストール\n",
    "必要なライブラリをインストールし、実行環境のバージョンを統一します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2db292-6d72-4177-b832-62c96fb9c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Google colab環境であるか判定\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # ライブラリのインストール\n",
    "    %pip install --no-warn-conflicts torch==2.1.1 torchvision==0.16.1 nltk==3.8.1 janome==0.5.0 numpy\n",
    "else:\n",
    "    print(\"Not Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a1670-fcc4-4287-bebc-baec24f4331b",
   "metadata": {},
   "source": [
    "### ドライブのマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24cebe-c37d-4fa4-9537-13f8a183f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab環境であるか判定\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # マウントを行う\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "else:\n",
    "    print(\"Not Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82cddb-78af-434f-846e-7babd2621629",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac1120b-aba9-4a81-b84c-f4ad3bbf4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.request\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "from nltk import tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e325a-704b-485d-94cb-3ec2f1ae4659",
   "metadata": {},
   "source": [
    "## データ収集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d8be6-1889-45cc-bf70-764500c5ff67",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "コーディング試験Chapter11-2で使用したLivedoorニュースコーパスをダウンロードして使用します。\n",
    "インターネット上に公開されているデータセットを以下のコードでダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2dc26-7ad7-4273-a847-6774c26df55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_ROOT = \"/content/drive/MyDrive/product_assignment/\"\n",
    "TARGZ_PATH = PRJ_ROOT + \"ldcc-20140209.tar.gz\"\n",
    "\n",
    "with urllib.request.urlopen(\"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\") as res:\n",
    "    with open(TARGZ_PATH, \"wb\") as f:\n",
    "        f.write(res.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39aac8f-ec87-4dfc-86e8-06940dfe2928",
   "metadata": {},
   "source": [
    "ダウンロードしたファイルは圧縮されているので、作業フォルダに展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740385e7-eba5-4411-b3e1-6b88dce0a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(TARGZ_PATH)\n",
    "tar.extractall(PRJ_ROOT)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7af6e-5198-4a85-932a-dc23d1ffda37",
   "metadata": {},
   "source": [
    "### データセットの作成\n",
    "カテゴリをラベル、ファイル内の文章をデータとしてそれらが対になったデータをCSV形式にして保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d448a2-2841-473b-866d-eaf89a5c437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm # 進捗バーを表示\n",
    "\n",
    "# 展開したテキスト群が置かれている親ディレクトリ\n",
    "DATA_DIR = PRJ_ROOT + 'text/'\n",
    "\n",
    "# カテゴリ名（サブディレクトリ）のリストを取得\n",
    "# 不要なファイル（例：LICENSE.txt）は除外\n",
    "categories = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "print(\"対象カテゴリ：\", categories)\n",
    "\n",
    "# 最終的にDataFrameにするための、行データ（辞書）を格納するためのリスト\n",
    "all_data = []\n",
    "\n",
    "# tqdmを使って進捗を表示しながらカテゴリごとにループ\n",
    "for category in tqdm(categories, desc=\"カテゴリ処理中\"):\n",
    "    category_path = os.path.join(data_dir, category)\n",
    "\n",
    "    files = os.listdir(category_path)\n",
    "    for file_name in files:\n",
    "        # category内のREADME.mdはスキップ\n",
    "        if file_name.endwith(\".txt\"):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "\n",
    "            try: \n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    # 最初の2行はURLとタイムスタンプなので読み飛ばし、3行目以降を本文として取得\n",
    "                    lines = f.readlines()\n",
    "                    text_body = \"\".join(lines[2:]).strip()\n",
    "\n",
    "                    # ラベル（カテゴリ名）とテキスト本文を辞書としてリストに追加\n",
    "                    all_data.append( {'label': category, 'text': text_body} )\n",
    "            except Exception as e:\n",
    "                print(f\"Error readin {file_path}: {e}\")\n",
    "\n",
    "# ループ完了後、リストから一気にDataFrameを作成\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# 作成したDataFrameをCSVとして保存（インデックスは不要なのでindexにはFalseを設定）\n",
    "df.to_csv(DATA_DIR + \"livedoor_news_corpus.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\nCSVファイルの作成が完了しました。\")\n",
    "print(\"データ件数：\", len(df))\n",
    "print(\"Head：\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0ae41-808d-436e-91f2-d3c7776e13af",
   "metadata": {},
   "source": [
    "### 言語データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8875f7a2-1326-433f-b7bd-a59f90214c7f",
   "metadata": {},
   "source": [
    "日本語を形態素解析して単語表層形に分かち書きします。\n",
    "\n",
    "そのうえで単語をIDに変換します。`\"CUDA out of memory\"` の回避のために文章が512文字を超えた場合には切り詰めを行いました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f7665-cd76-46d6-86ab-f8bd1983d6ff",
   "metadata": {},
   "source": [
    "#### 日本語の分かち書きメソッド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d8597-44b1-400b-a30d-8e767eed054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakati = Tokenizer()\n",
    "\n",
    "\"\"\" 日本語のトークン化 \"\"\"\n",
    "def tokenize_ja(sentences_list):\n",
    "    wakati_list = []\n",
    "    print(\"トークン処理を開始します。\")\n",
    "    for sentence in tqdm(sentences_list):\n",
    "        # tokenizeから返される表層形を分かち書きリストに登録\n",
    "        wakati_list.append([item.surface for item in wakati.tokenize(sentence)])\n",
    "    return wakati_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3f4da-d807-42bf-aef8-165b98851d0a",
   "metadata": {},
   "source": [
    "#### 単語からIDへの辞書を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ea4ea-ad7f-4dc2-aa17-1369a308af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 単語からIDへの辞書を作成 \"\"\"\n",
    "def create_word_id_dict(sentences):\n",
    "    word_to_id = {}  # 単語からIDへの変換辞書\n",
    "    id_to_word = {}  # IDから単語への逆引き辞書\n",
    "    # 0はパディング／未知語用に予約\n",
    "    word_to_id['<PAD>/<UNK>'] = 0\n",
    "    id_to_word[0] = '<PAD>/<UNK>'\n",
    "\n",
    "    # すべての文章をループ  \n",
    "    for sentence in sentences:\n",
    "        # 文章内の各単語をループ\n",
    "        for word in sentence:\n",
    "            # もし単語がまだ辞書に登録されていなければ、新しいIDを割り振る、\n",
    "            if word not in word_to_id:\n",
    "                # 新しいIDとして、現在の辞書のサイズ（登録済みの単語数）を使用する\n",
    "                tmp_id = len(word_to_id)\n",
    "                word_to_id[word] = tmp_id\n",
    "                id_to_word[tmp_id] = word\n",
    "\n",
    "    # (単語をキー、IDをバリューとする辞書, IDをキー、単語をバリューとする辞書)のタプルを返す\n",
    "    return word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315fd19-ecae-4ad4-986e-2731cca61155",
   "metadata": {},
   "source": [
    "#### 文章をID列に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022f826-c6e1-46d2-ae42-da934495e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 単語で構成された文章のリストを対応するIDのリストに変換 \"\"\"\n",
    "def convert_sentences_to_ids(sentences, word_to_id):\n",
    "    sentence_id_list = []\n",
    "    for sentence in sentences:\n",
    "        # dict.get(key, default)メソッドによって、未知語でもエラーにならずにデフォルトである<UNK>のIDを返す\n",
    "        sentence_ids = [word_to_id.get(word, 0) for word in sentence]\n",
    "        sentence_id_list.append( sentence_ids )\n",
    "\n",
    "    # IDに変換された文章のリストを返す \n",
    "    return sentence_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acd2c7-ceea-4327-ad64-34d7ad908806",
   "metadata": {},
   "source": [
    "#### 文章のパディング処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8cb60-622c-4f81-9541-ca5a86bda9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" IDに変換され文章のリスト\"に対して、paddingと打ち切り処理を行う \"\"\"\n",
    "def padding_and_truncate_sentence(sentences, max_len=512):\n",
    "    # 処理が行われた後の文章IDを格納するリスト\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # １．打ち切り\n",
    "        # 文章の長さが max_lenを超える場合、末尾から max_len分だけを取得します。\n",
    "        # 文章の末尾に重重要な情報含まれる場合が多いため、前から切り捨てます\n",
    "        # 改善モデルにおけるMultiheadAttention層が内部で行う計算で、\n",
    "        # 巨大な行列を作成しようとしてGPUのメモリが足りなくなる問題への対応として実施しました。\n",
    "        sentence = sentence[-max_len:]\n",
    "\n",
    "        # ２．padding\n",
    "        # 文章の長さがmax_lenに満たない場合、差分を計算\n",
    "        padding_size = max_len - len(sentence)\n",
    "\n",
    "        # 足りない分だけ <PAD>のIDのリストを作成し、文章の前方に連結\n",
    "        padding = [0] * padding_size\n",
    "        processed_sentences.append(padding + sentence)\n",
    "\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a483b-33c7-44e5-8ec7-04304b009155",
   "metadata": {},
   "source": [
    "#### 前処理の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fbcda-1a31-4959-8c39-bb183cca447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生のCSVの読み込み\n",
    "df = pd.read_csv(PRJ_ROOT + \"livedoor_news_corpus.csv\")\n",
    "\n",
    "# 文章カテゴリ（ラベル）をID化\n",
    "label_to_id = {label: i for i, label in enumerate(df['label'].unique())}\n",
    "id_to_label = {i: label for i, label in enumerate(df['label'].unique())}\n",
    "\n",
    "# テキストの分かち書き\n",
    "ja_sentences = tokenize_ja(df[\"text\"].tolist())\n",
    "\n",
    "# 単語辞書の作成\n",
    "word_to_id, id_to_word = create_word_id_dict(ja_sentences)\n",
    "\n",
    "# 文章をID列に変換\n",
    "sentence_ids = convert_sentences_to_ids(ja_sentences, word_to_id)\n",
    "\n",
    "# padding処理\n",
    "padded_ids = padding_and_truncate_sentence(sentence_ids)\n",
    "\n",
    "# データをまとめた辞書を作成\n",
    "processed_data = {\n",
    "    'padded_ids': padded_ids,\n",
    "    'labels': df['label_id'].tolist(),\n",
    "    'word_to_id': word_to_id,\n",
    "    'id_to_word': id_to_word,\n",
    "    'label_to_id': label_to_id,\n",
    "    'id_to_label': id_to_label,\n",
    "}\n",
    "\n",
    "# 学習用データはpickle形式にして保存する\n",
    "with open(PKL_FILE_PATH + 'processed_data_maxlen512.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_data, f)\n",
    "\n",
    "print(f\"保存ファイル: processed_data_maxlen512.pkl\")\n",
    "print(f\"語彙数: {len(word_to_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b123f0-e9f3-4cb6-89a0-befbe833adc4",
   "metadata": {},
   "source": [
    "## 前処理データの読み込みとデータセットの分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95c48b-5ef6-4bdb-8b32-9102914c8fe0",
   "metadata": {},
   "source": [
    "今回はニュースカテゴリの分類という分類問題を扱います。分類問題に対しては、各カテゴリのデータ比率を保ったまま分割する層化サンプリング（Stratified Sampling） を行うのが最適な方法です。\n",
    "\n",
    "もし単純なランダムサンプリングの場合、特定のカテゴリのデータがテストデータにほとんど含まれない、といった事故が生じる可能性があります。\n",
    "\n",
    "層化サンプリングではデータが少ないカテゴリも訓練・検証・テストの各データセットに**均等**に分配されます。そのため、そのような事故を回避でき、信頼性の高いモデル評価ができるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14477b-6392-4428-a8f4-bd825331c40d",
   "metadata": {},
   "source": [
    "### 前処理データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d2332-5cf3-4818-83ce-8882f0b0886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pklファイルから前処理済みデータを読み込む\n",
    "PKL_FILE_PATH = '/content/drive/MyDrive/deeplearning/processed_data_maxlen512.pkl'\n",
    "with open(PKL_FILE_PATH, 'rb') as f: # 'rb'：バイナリ読み込みモード\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# dataは辞書型オブジェクトとして保存\n",
    "padded_ids = data['padded_ids']\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22213b6-87f4-47a5-a4a7-e0fb7be1f5fd",
   "metadata": {},
   "source": [
    "### データセットの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724168c-2cc7-4b10-8c14-3904560c0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを訓練・検証・テスト用に分割\n",
    "# ※この時点ではまだPythonのリスト型として扱う\n",
    "\n",
    "# 1. 全体を「訓練＋検証用」（90%）と「テスト用」（10%）に分割\n",
    "# test_size=0.1: 全体の10％をテストデータとする\n",
    "# random_state=42: 乱数を固定し、何度実行しても同じ分割結果とする（再現性の確保）\n",
    "# stratify=labels: 元のデータのラベル比率を保ったまま分割する\n",
    "train_val_ids, test_ids, train_val_labels, test_labels = train_test_split(\n",
    "    padded_ids, labels, test_size=0.1, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# 2. 次に「訓練＋検証用」のデータを「訓訓用（80%）」と「検証用（10％）」に分割\n",
    "# train_valデータは全体の90%なので、そのうちの1/9を検証用にすると、全体から見て10%分相当となる\n",
    "# 0.9 * 1/9 = 0.1\n",
    "train_ids, val_ids, train_labels, val_labels = train_test_split(\n",
    "    train_val_ids, train_val_labels, test_size=(1/9), random_state=42, stratify=train_val_labels\n",
    ")\n",
    "\n",
    "# PyTorchのDatasetクラスの定義\n",
    "# Datasetクラス：データとそのラベルと保持し、インデックスを指定して１つずつ取り出すための器\n",
    "class LivedoorTensorDataset(Dataset):\n",
    "    def __init__(self, ids, labels):\n",
    "        # コンストではｈクタ、IDのリストとラベルのリストをインスタンス変数として保持\n",
    "        self.ids = ids\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        # データセット全体のサンプル数を取得\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 指定されたindexのデータを取得。DataLoaderから内部的に呼び出される\n",
    "        # ここでPythonのリスト型からPyTorchが扱えるTensor型へと変換している\n",
    "        # dtype=torch.long：整数ID（単語IDやラベルIDを扱う際の標準的なデータ型）\n",
    "        input_ids = torch.tensor(self.ids[index], dtype=torch.long)\n",
    "        label_id  = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        return input_ids, label_id\n",
    "\n",
    "# 各データ分割に対応するDatasetインスタンスの作成\n",
    "# 上記で定義したDatasetクラスを使い、訓練・検証・テストそれぞれのデータセットオブジェクトを作成\n",
    "train_dataset = LivedoorTensorDataset(train_ids, train_labels)\n",
    "val_dataset   = LivedoorTensorDataset(val_ids,   val_labels)\n",
    "test_dataset  = LivedoorTensorDataset(test_ids,  test_labels)\n",
    "\n",
    "# DataLoaderの作成\n",
    "# DataLoaderはDatasetをラップし、ミニバッチ処理、データのシャッフル、並列読み込みなどを効率的に行う\n",
    "BATCH_SIZE = 16 # 一度にモデルを投入するデータ数（バッチサイズ）\n",
    "\n",
    "# 訓練用DataLoader：データをシャッフルすることで、学習の偏りを防ぎ、モデルの汎用性を向上させる\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# 検証用とテスト用DataLoader：評価時はデータの順序を維持するため、シャッフルは不要\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# モデルのハイパーパラメータ\n",
    "# データから自動的に設定\n",
    "vocab_size = len(data['word_to_id']) # 語彙数。単語とIDの対応辞書のサイズから取得\n",
    "num_classes = len(set(labels)) # 分類クラス数。ラベルの種類数をset()で重複を除いてカウント\n",
    "\n",
    "# 人間が設定\n",
    "embedding_dim = 256 # 単語をベクトル表現に変換した際のベクトルの次元数\n",
    "hidden_dim = 256 # CNNやGRUの中間層（隠れ層）の次元数。モデルの表現力に影響\n",
    "\n",
    "# 設定したパラメータを画面に出力して確認\n",
    "print(f\"語彙数 (vocab_size): {vocab_size}\")\n",
    "print(f\"分類クラス数 (num_classes): {num_classes}\")\n",
    "print(f\"単語ベクトルの次元数 (embedding_dim): {embedding_dim}\")\n",
    "print(f\"隠れ層の次元数 (hidden_dim): {hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14948bf-a9af-4826-8d1a-c7365683e60d",
   "metadata": {},
   "source": [
    "## アルゴリズム選択（ベースラインモデル）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530be25b-0134-4803-8d29-2edceda1879a",
   "metadata": {},
   "source": [
    "### ベースラインモデル設計"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14168920-0431-47b7-8474-444f176b3497",
   "metadata": {},
   "source": [
    "　最初にCNNとGRUを1つのディープラーニングモデルの中に層（レイヤー）として組み込み、それぞれの長所を活かす**ハイブリッド**な構造を採用しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd55dae-1fd6-4d64-9be1-223bc3d2cecf",
   "metadata": {},
   "source": [
    "今回はLSTMではなく**GRU**を採用しました。\n",
    "\n",
    "GRUはLSTMと比べてゲートの数が少なく構造がシンプルなため、**計算コストが低く学習が速い**傾向にあります。\n",
    "\n",
    "それでいて、多くのタスクで**LSTMと同等**の性能を発揮することが知られています。\n",
    "\n",
    "今回の課題では、**計算効率**と**実装の容易さ**を考慮し、RNN系手法としてGRUを採用しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1dff5-81a8-4512-a68b-cfd3eabaaa07",
   "metadata": {},
   "source": [
    "CNNは入力された単語ベクトルの並びに対して、**局所的な特徴（n-gramのような短い単語の組み合わせ）**を抽出する役割を果たします。\n",
    "\n",
    "例えば、「とても面白い」や「つまらない」といったキーフレーズを効率的に見つけ出す役割を担います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e059d5f-c942-4669-af85-d8723e54b180",
   "metadata": {},
   "source": [
    "CNNとGRUの組み合わせを選んだ理由としてこれらの手法の以下の特徴に着目しました：\n",
    "\n",
    "* CNNの長所: 文中の重要なキーワードやフレーズ（局所的な特徴）を効率的に捉えることができる\n",
    "\n",
    "* GRUの長所: RNN系列の手法として、単語の系列（シーケンス）の文脈や順序関係を効果的に捉えることができる\n",
    "\n",
    "この2つを組み合わせることで、**「文章中の重要な部分（CNNが担当）が、どのような文脈で登場したか（GRUが担当）」**を同時に学習できるモデルを作ることができると考えました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e23a37-4ca6-4acc-87be-fc30386ebf50",
   "metadata": {},
   "source": [
    "構築したニューラルネットワークは以下のような**4つの中間層**からなる構成となっています：\n",
    "\n",
    "1. **Embedding層**: 単語をベクトルに変換する層\n",
    "2. **CNN層** (1次元CNN): 特徴を抽出する層\n",
    "3. **GRU層**: 系列情報を処理する再帰的な層\n",
    "4. **全結合層**: 最終的な分類を行う層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd43084-4595-48ca-be86-857b5df1a4f7",
   "metadata": {},
   "source": [
    "### ベースラインモデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4bf40-7d8e-4751-a846-ec11ee35d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ベースラインモデル \"\"\"\n",
    "class CNN_GRU_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    CNNで系列データから局所的な特徴を抽出します。\n",
    "    GRUでその特徴の時間的な依存関係を学習します。\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        \"\"\"\n",
    "        コンストラクタ\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): 語彙数。入力される単語の種類の数。\n",
    "            embedding_dim (int): 単語埋め込みベクトルの次元数。\n",
    "            hidden_dim (int): CNNの出力チャネル数。GRUの隠れ状態の次元数。\n",
    "            num_classes (int): 出力クラス数。分類したいカテゴリの数。\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Embedding層\n",
    "        # 単語IDの系列を単語埋め込みに変換\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # 2. 1次元CNN層（Convolutional Neural Network）\n",
    "        # 埋め込みベクトルの系列から、n-gramのような局所的な特徴を抽出\n",
    "        # in_channels: 入力チャネル数（埋め込み次元数）\n",
    "        # out_channels: 出力チャネル数（抽出される特徴マップの数 = hidden_dim）\n",
    "        # kernel_size=3: ３つの連続する単語ベクトルを一度に見る（3-gramに相当）\n",
    "        # padding=1: 畳み込み後も系列長を変化させないためにpaddingを追加\n",
    "        self.cnn = nn.Conv1d(in_channels=embedding_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU() # 活性化関数\n",
    "\n",
    "        # 3. GRU（Gated Recurrent Unit）\n",
    "        # CNNが抽出した特徴系列を入力とし、時間的な依存関係を学習\n",
    "        # input_size: 各タイムステップにおける入力特徴の次元数（＝CNNの出力チャネル数）\n",
    "        # hidden_size: GRUの隠れ状態ベクトルの次元数\n",
    "        # batch_size=True: 入力テンソルの形状を（batch_size, seq_len, input_size）として扱う\n",
    "        self.gru = nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, batch_size=True)\n",
    "\n",
    "        # 4. 全結合層（Fully Connected Layer）\n",
    "        # GRUから得られた最終的な文脈ベクトルを、指定されたクラス数にマッピングし、分類スコアを出力\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "\n",
    "        Args: \n",
    "            x (torch.Tensor): 入力データ。単語IDの系列\n",
    "                            　形状：（batch_size, seq_len）\n",
    "        Returns:\n",
    "            torch.Tensor: 各クラスに対する分類スコア\n",
    "                        　形状：（batch_size, num_clases）\n",
    "        \"\"\"\n",
    "        # 1. Embedding\n",
    "        # x の形状：（batch_size, seq_len）\n",
    "        x = self.embedding(x)   # -> (batch_size, seq_len, embedding_len)\n",
    "\n",
    "        # 2. CNN\n",
    "        # Conv1dは 入力として(batch, channels, seq_len) の形状を受け付けるため、埋め込みベクトルの次元を入れ替える\n",
    "        # (batch_size, seq_len, embedding_dim) -> (batch_size, embedding_dim, seq_len)\n",
    "        #       0         1            2                0            2           1 \n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # 畳み込み層とのの活性化関数を適用\n",
    "        x = self.cnn(x)         # -> (batch_size, hidden_dim, seq_len)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # 3. GRU\n",
    "        # GRUの入力（batch_first=True）は（batch, seq, feature）の形状を受け付けるため、再度次元を入れ替える\n",
    "        # (batch_size, hidden_size, seq_len) -> (batch_size, seq_len, hidden_dim)\n",
    "        #       0         1            2             0          2          1 \n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # GRUは全てのタイムステップの出力（output）と最期のタイムステップの隠れ状態（h_n）を返す\n",
    "        # ここでは文脈全体を返す最後の隠れ状態のみ使用\n",
    "        _, h_n = self.gru(x) # h_nの形状：(num_layers, batch_size, hidden_dim) \n",
    "\n",
    "        # 4. 全結合層\n",
    "        # GRuの最後の隠れ状態の次元（num_layer）を解除し、（batch_size, hidden_dim）の形状に整形\n",
    "        x = h_n.squeeze(0) # -> (batch_size, hidden_dim)\n",
    "\n",
    "        # 全結合層に入力し、最終的なクラススコアを得ます\n",
    "        out = self.fc(x) # -> (batch_size, num_classes)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85027378-8fcd-437a-9e22-33b46823480b",
   "metadata": {},
   "source": [
    "### ベースラインモデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093cf0d-98ed-4daa-afe7-6c020c2009be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行環境（GPU／CPU）の確認と設定\n",
    "# GPUが利用可能か確認し、利用可能なら \"cuda\"、そうでなければ \"cpu\" をdeviceに設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# CNN_GRU_Modelのインスタンスを生成し、.to(device)で指定したデバイスにモデルを転送\n",
    "# モデルのパラメータ（重み）や計算が、指定したデバイスで実施されるようにする\n",
    "model = CNN_GRU_Model(vocab_size, embedding_dim, hidden_dim, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# 最適化手法と損失関数の定義\n",
    "# 最適化アルゴリズムとしてAdamを使用\n",
    "# model.parameters() を渡すことで、モデルが持つすべてのパラメータを最適化の対象として登録\n",
    "# lrは学習率（learning rate）で、パラメータ更新のステップ幅を決定\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 損失関数としてクロスエントロピー損失を定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# モデルの保存設定と学習ループの準備\n",
    "# 才能の検証損失を保存する変数を初期化することによって、検証データの損失が改善した場合にのみモデルを保存する\n",
    "# 早期終了（Early Stopping）に近い戦略\n",
    "best_valid_loss = np.inf\n",
    "MODEL_SAVE_PATH = PRJ_ROOT + 'baseline_model_best_model.pth' # 最良モデルの保存先ファイルパス\n",
    "\n",
    "n_epoch = 10 # 学習エポック数\n",
    "for epoch in range(n_epoch):\n",
    "    # 各エポックの開始時に、訓練データと検証データの損失と正解数をリセット\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    accuracy_train = 0\n",
    "    accuracy_valid = 0\n",
    "\n",
    "    # 訓練モード\n",
    "    # model.train()を呼び出し、モデルを「訓練モード」に切り替える\n",
    "    # Dropout層やBatchNorm層などが訓練時の挙動となる\n",
    "    model.train()\n",
    "    for x,t in train_loader: # DataLoaderからミニバッチを1件ずつ取り出す\n",
    "        # データをモデルと同じデバイスに転送\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        # 前のバッチの勾配が累積しないように勾配をリセットする。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播\n",
    "        output = model(x)\n",
    "\n",
    "        # 損失計算：モデルの出力と正解ラベルとを比較し、損失を計算\n",
    "        loss = criterion(output, t)\n",
    "        # 逆伝播：損失に基づいて、各パラメータの勾配を計算\n",
    "        loss.backward()\n",
    "\n",
    "        # パラメータ更新：計算された勾配を基に、オプティマイザがモデルのパラメータを更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # 予測ラベルを計算。出力が最も大きいクラスを予測結果とするる\n",
    "        pred = output.argmax(dim=1)\n",
    "\n",
    "        # このバッチでの損失と正解数を、エポック全体の集計に加算\n",
    "        # .item()はテンソルからPythonのスカラー値を取り出す\n",
    "        loss_train += loss.item()\n",
    "        accuracy_train += torch.sum(pred == t.data)\n",
    "    \n",
    "    # 検証モード\n",
    "    # model.eval()を呼び出し、モデルを「検証モード」に切り替える\n",
    "    model.eval()\n",
    "\n",
    "    # 検証ではパラメータ更新はおこなわず、メモリ消費量を削減し、計算速度は向上する\n",
    "    with torch.no_grad():\n",
    "        for x,t in val_loader:\n",
    "            # データをデバイスに転送\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            # 順伝播\n",
    "            output = model(x)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(output, t)\n",
    "            \n",
    "            # 予測ラベルを計算\n",
    "            pred = output.argmax(dim=1)\n",
    "\n",
    "            # 損失と正解数を加算\n",
    "            loss_valid += loss.item()\n",
    "            # モデルの予測と正解ラベルとが等しいものの個数をカウントして足し合わせる\n",
    "            accuracy_valid += torch.sum(pred == t.data)\n",
    "    \n",
    "    # エポックごとの結果を計算して表示する\n",
    "    avg_loss_train = loss_train / len(train_loader)\n",
    "    avg_loss_valid = loss_valid / len(val_loader)\n",
    "    avg_acc_train = accuracy_train / len(train_dataset)\n",
    "    avg_acc_valid = accuracy_valid / len(val_dataset)\n",
    "\n",
    "    # 結果を整形して表示\n",
    "    print(\n",
    "        f\"| epoch {epoch+1:2d} | train loss {avg_loss_train:.4f}, acc {avg_acc_train:.4f} \"\n",
    "        f\"| valid loss {avg_loss_valid:.4f}, acc {avg_acc_valid:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 最良モデルの保存\n",
    "    # 検証データの損失が、これまでの最小値を更新した場合\n",
    "    if avg_loss_valid < best_valid_loss:\n",
    "        print(f\"Validation loss improved ({best_valid_loss:.4f} --> {avg_loss_valid:.4f}). Saving model...\")\n",
    "        best_valid_loss = avg_loss_valid # 最小損失を更新\n",
    "\n",
    "        # モデルのパラメータ（重み）のみを保存\n",
    "        torch.ave(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"\\nTraining finished. Best model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcf5ae-bf5e-4a90-83cf-9c8b0678ddc3",
   "metadata": {},
   "source": [
    "### ベースラインモデルの評価 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff25b67-e2b4-450e-8321-f9f6d02e00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価と結果の可視化\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\" '{PRJ_ROOT + 'baseline_model_best_model.pth'}' を読み込んでいます...\")\n",
    "with open(PRJ_ROOT + 'baseline_model_best_model.pth', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# pklファイル内のデータから、IDとカテゴリ名の対応辞書を再取得\n",
    "# 評価レポートやグラフのラベルとして使用\n",
    "id_to_label = data['id_to_label']\n",
    "\n",
    "# 評価レポート用に、カテゴリ名のリストもここから作成\n",
    "category_names = list(id_to_label.values())\n",
    "\n",
    "# 全ての予測結果と正解ラベルを格納するための空のリストを準備\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# モデルを「評価モード」に切り替える\n",
    "model.eval()\n",
    "\n",
    "#勾配計算を無効にして計算リソースを節約\n",
    "with torch.no_grad():\n",
    "    # テストデータ用のDataLoaderからミニバッチを１件ずつ取り出す\n",
    "    for x,t in test_loader:\n",
    "        # データをモデルと同じデバイにに転送\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        # モデルにデータを入力し、順伝播させる\n",
    "        output = model(x)\n",
    "\n",
    "        # 最もスコアの高いクラスのインデックスを予測結果とする\n",
    "        pred = output.argmax(dim=1)\n",
    "\n",
    "        # 予測結果と正解ラベルをリストに追加\n",
    "        #　scikit-learnで計算するために、GPUのTensorからCPU上のリストに変換する\n",
    "        # .cpu()でCPUに転送し、.tolist()でPythonのリストに変換\n",
    "        # \n",
    "        all_preds.extend( pred.cpu().tolist() )\n",
    "        all_labels.extend( t.cpu().tolist() )\n",
    "        '''\n",
    "          当初は.numpy()でNumPy配列に変換しようとしていたが、RuntimeError: Numpy is not availableが発生した。\n",
    "          これは、NumPyライブラリが見つからない、または利用できない」ことを示している。\n",
    "          Colab上にプリインストールされていたNumPyが他のライブラリとの兼ね合いなどで不安定になったと思われる。\n",
    "          ランタイムの再起動／リセットを試したが、改善しなかった。\n",
    "          対応策として、NumPyを一切経由せず、Tensorを直接Pythonの標準的なリストに変換する .tolist() メソッドを使用した。\n",
    "          scikit-learnの評価関数はNumPy配列だけでなく、Pythonのリストも受け付けるため、この方法で動作。\n",
    "        ''' \n",
    "\n",
    "# 正解率（Accuracy）の計算\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 適合率（Precision）、再現率（Recall）、F1スコア（F1-Score）を含むレポートを表示\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(all_labels, all_preds, target_names=category_names)\n",
    "\n",
    "# 結果をテキストファイルに保存\n",
    "with open(DATA_DIR + \"CNN_GRU_test_results.txt\",\"w\") as f:\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# 混合行列（Confusion Matrix）の計算と可視化\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# numpy配列のままだと軸が数字で見づらいため、PandasのDataFrameに変換\n",
    "# indexとcolumnsにカテゴリ名を設定\n",
    "cm_df = pd.DataFrame(cm, index=category_names, columns=category_names)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10,8)) # グラフのサイズを指定\n",
    "# seabornのheatmap関数を使って、混合行列をヒートマップとして描画\n",
    "# annot=True：各セルに数値を表示\n",
    "# fmt='d': 数値を整数で表示\n",
    "# cmap='Greens': 色のテーマを指定\n",
    "sns.heatmap(cm_df, annot=True, cmap='Greens')\n",
    "plt.title('Confusion Matrix') # グラフのタイトル\n",
    "plt.ylabel('True Label') # Y軸のラベル\n",
    "plt.xlabel('Predicted Label') # X軸のラベル\n",
    "\n",
    "plt.tight_layout() # ラベルがグラフ領域からはみ出ないように自動調整\n",
    "\n",
    "# 混合行列を画像ファイルとして保存\n",
    "plt.savefig(PRJ_ROOT + \"CNN_GRU_confusion_matrix.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e175f-332a-40da-a0a4-33de450ddf0f",
   "metadata": {},
   "source": [
    "#### ベースラインモデルの予測結果の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34f7ab-36b2-4ea0-a788-5c6358def59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果をNumPyファイルとして保存\n",
    "np.save(PRJ_ROOT + 'cnn_predictions.npy', np.array(all_preds))\n",
    "print(\"ベースラインモデルの予測結果を cnn_predictions.npy として保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76ba50-9667-4743-b3a6-9886a2b42462",
   "metadata": {},
   "source": [
    "### ベースラインモデルの考察"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49eaf572-39ce-4f71-bda7-29e54689e88a",
   "metadata": {},
   "source": [
    "Classification Reportの解釈\n",
    "\n",
    "Precision (適合率): モデルが「このカテゴリだ！」と予測したもののうち、どれだけが本当に正しかったかを示す割合です。この値が高いカテゴリは、モデルの予測の信頼性が高いことを意味します。\n",
    "\n",
    "Recall (再現率): 実際のそのカテゴリのデータ全体のうち、どれだけをモデルが見つけ出せたかを示す割合です。この値が高いカテゴリは、見逃しが少ないことを意味します。\n",
    "\n",
    "F1-score (F1スコア): PrecisionとRecallのバランスを取った総合的な指標です。両方の性能をバランス良く評価したい場合に重視します。\n",
    "\n",
    "Support: そのカテゴリのテストデータが何件あったかを示します。\n",
    "\n",
    "良好な点 (モデルが得意なカテゴリ)\n",
    "smax (スマホ情報): f1-scoreが0.99と、ほぼ完璧に分類できています。専門用語が多く、他のカテゴリと区別しやすいと考えられます。\n",
    "\n",
    "it-life-hack (ITニュース): f1-scoreが0.94と、こちらも非常に高い精度です。\n",
    "\n",
    "kaden-channel (家電チャンネル): f1-scoreが0.90と、これも得意なようです。\n",
    "\n",
    "全体的に、IT・ガジェット系の専門的な話題は、特徴的な単語が多いためモデルが非常に得意としていることが分かります。\n",
    "\n",
    "課題となる点 (モデルが苦手なカテゴリ)\n",
    "livedoor-homme (男性向け情報): f1-scoreが0.50と、最も低い値になっています。\n",
    "\n",
    "特に**recallが0.39**と低いのが致命的です。これは、実際のlivedoor-hommeの記事の約6割を、他のカテゴリだと間違えてしまっている（見逃している）ことを意味します。\n",
    "\n",
    "原因の推測: 「男性向け」というテーマは非常に幅広く、他のカテゴリ（topic-newsやpeachyなど）と話題が重複しやすいため、モデルが明確な特徴を見つけにくいのかもしれません。\n",
    "\n",
    "peachy (女性向け総合情報): f1-scoreが0.68と、2番目に低い値です。\n",
    "\n",
    "こちらは**precisionが0.63と低めです。これは、peachyだと予測したもののうち、4割近くが実際は別のカテゴリだった**、ということを意味します。livedoor-hommeとは逆の傾向です。\n",
    "\n",
    "原因の推測: こちらもテーマが幅広いため、他のカテゴリの記事を「これもpeachyっぽい」と誤って分類してしまっていると考えられます。\n",
    "\n",
    "## 今後の改善案\n",
    "今回の結果は成功ですが、さらに精度を上げるための次のステップとして、以下のようなことが考えられます。\n",
    "\n",
    "混同行列の確認: 可視化した混同行列（confusion_matrix.png）を見てみましょう。livedoor-hommeが、具体的にどのカテゴリと間違えられているかが一目で分かります。\n",
    "\n",
    "Self-Attentionモデルの導入: 次のステップとして計画していた、Self-Attentionを用いたモデルを試す価値は非常に高いです。CNNよりも文脈を広く捉えることができるため、livedoor-hommeやpeachyのような、単語の組み合わせや文脈のニュアンスが重要なカテゴリの分類精度が向上する可能性があります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff1332-889f-4ab0-9251-493304fd5b35",
   "metadata": {},
   "source": [
    "## アルゴリズム選択（改善モデル）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52470d96-8193-460c-9cc8-9cfbf6b6ee25",
   "metadata": {},
   "source": [
    "### 改善モデル設計"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54fca48-3eb6-4e59-9575-96959e54a3ad",
   "metadata": {},
   "source": [
    "CNN層が担う「文中の重要な部分（キーフレーズなど）を見つけ出す」という役割は、Attentionメカニズムで代替することが可能であると考えました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32677fe7-3228-48ca-8a8e-2e0d2e2c1074",
   "metadata": {},
   "source": [
    "##### 自然言語の特徴抽出におけるCNNとAttentionの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dab21a-a01d-4dc4-9a32-052c0caf4698",
   "metadata": {},
   "source": [
    "* CNN層\n",
    "\n",
    "　CNNは、**「位置的に近い単語の組み合わせ」**に注目します。カーネル（フィルター）と呼ばれる固定サイズの窓を文頭からスライドさせ、局所的なパターン（例：「とても 面白い」「価格が 高い」など）を検出します。\n",
    "\n",
    "**強み**: 計算が**高速**で、n-gramのような**局所的**な特徴を捉えるのが得意。\n",
    "\n",
    "**弱み**: 窓のサイズが固定されているため、**遠く離れた**単語同士の関係性を捉えるのが苦手。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1879ea-c75c-4b9b-a4db-0d8df1f52650",
   "metadata": {},
   "source": [
    "* Attentionメカニズム\n",
    "\n",
    "　Attentionは、**「文脈上、どの単語が他の単語と関連が深いか」**に注目します。文中のある単語を処理する際に、他のすべての単語との関連度（Attentionスコア）を計算し、スコアが高い単語の情報を重点的に利用します。\n",
    "\n",
    "**強み**: 距離に関係なく、文全体の文脈から動的に単語の重要度を判断できる。「その」という指示語が文頭のどの名詞を指しているか、といった**長期的な依存関係**を捉えるのが非常に得意。\n",
    "\n",
    "**弱み**: 計算量が系列長の2乗に比例して増える（$O(n^2)$ ）ため、非常に長い文章では計算コストが高くなることがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb5530-5da4-4b7f-9329-4a38b1b81902",
   "metadata": {},
   "source": [
    "　Attentionは、CNNのように局所的な関係に限定されません。文脈に応じて、隣り合った単語に高いスコアを与えることも、遠く離れた単語に高いスコアを与えることもできます。\n",
    "\n",
    "　CNNの代わりにAttentionを特徴抽出に利用することで、**文脈情報**をより加味した分類を実現することができ、livedoor-hommeやpeachyのような、**単語の組み合わせ**や**文脈のニュアンス**が重要なカテゴリの分類精度を向上できると考えました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5289b7-e3c4-4074-80a5-d564a65c4ac0",
   "metadata": {},
   "source": [
    "以下のような**4つの中間層**からなる構成のニューラルネットワークを改善モデルとして考案しました：\n",
    "\n",
    "1. **Embedding層**: 単語をベクトルに変換する層\n",
    "2. **Attentionメカニズム** (Self-Attention): 特徴を抽出する層\n",
    "3. **GRU層**: 系列情報を処理する再帰的な層\n",
    "4. **全結合層**: 最終的な分類を行う層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24e744-e586-4ee4-bbfc-fa20de362969",
   "metadata": {},
   "source": [
    "### 改善モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98884b4-d95f-454a-8f32-221589b4c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_GRU_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Self-Attention機構をGRU前段に組み込んだモデル\n",
    "    Attention層が入力シーケンス内の単語間の関連性を捉え、\n",
    "    GRUが時系列に処理することで、より高度な特徴抽出を目指す\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, num_heads=8):\n",
    "        \"\"\"\n",
    "        コンストラクタ\n",
    "\n",
    "        Args:  \n",
    "            Vocab_size (int): 語彙数\n",
    "            embedding_dim (int): 単語埋め込みベクトルの次元数。Attention層の入力次元数でもある\n",
    "            hidden_dim (int): GRUの隠れ状態の次元数\n",
    "            num_classes (int): 出力クラス数\n",
    "            num_heads (int): Multi-Head Attentionのヘッド数\n",
    "        \"\"\"\n",
    "        super(Attention_GRU_Model,self).__init__()\n",
    "\n",
    "        # 1. Embedding層\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # 2. Attention層（Multi-Head Self-Attention）\n",
    "        # 入力系列内の各単語が、他のどの単語に注目すべきかを学習します。\n",
    "        # embeded_dim: 入出力の次元数\n",
    "        # num_heads: 並列計算のためにAttentionの「ヘッド」をいくつに分割するかを設定\n",
    "        # batch_first=False: 入力の形式を（seq_len, batch_size, dim）に指定します。\n",
    "        self.multi_head_attention = nn.MultiheadAttention(\n",
    "            embed_dim=embedding_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=False\n",
    "        )\n",
    "\n",
    "        # 学習を安定させるためのレイヤ正規化\n",
    "        # Attention層に適用\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        # 3. GRU層\n",
    "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "\n",
    "        # 4. 全結合層\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensro): 入力データ。形状：(batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: 各クラスに対する分類スコア。形状：(batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(x) # -> (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # 2. Self-Attention\n",
    "        # MultiheadAttentionの入力形式 (seq_len, batch_size, dim)に合わせるため、次元を入れ替える\n",
    "        x_permuted = x.permute(1, 0, 2) # -> (seq_len, batch_size, embedding_dim)\n",
    "\n",
    "        # Self-Atttentionでは、Query, Key, Valueにすべて同じ入力（x_permuted）を用いる\n",
    "        # MultiheadAttentionの順伝播\n",
    "        attn_output, _ = self.multi_head_attention(query=x_permuted, key=x_permuted, value=x_permuted)\n",
    "\n",
    "        # 残差接続（residual Connection）とレイヤ正規化\n",
    "        # 入力 x_permuted をAttentionの出たた足し合わせることで、勾配消失を防ぐ\n",
    "        x = self.norm1(x_permuted + attn_output) # -> (seq_len, batch_size, embedding_dim)\n",
    "\n",
    "        # 3. GRU\n",
    "        # GRUの入力形式（batch_size, seq_len, dim）に戻すため、再度次元を入れ替える\n",
    "        x_permuted = x.permute(1, 0, 2) # -> (seq_len, batch_size, embedding_dim)\n",
    "\n",
    "        # GRU層に入力し、最後の隠れ状態 h_n を取得\n",
    "        _, h_n = self.gru(x) # h_n の形状：（num_layers, batch_size, hidden_dim)\n",
    "\n",
    "        # 4. 分類\n",
    "        x = h_n.squeeze(0) # -> (batch_size, hidden_dim)\n",
    "        # 全結合層で最終的なクラススコアを出力\n",
    "        out = self.fc(x) # -> (batch_size, num_classes)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d8479-3ae2-4a07-acce-1f22f9a6437b",
   "metadata": {},
   "source": [
    "### 改善モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccfa1d4-73a9-4faf-a932-d6382eda7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行環境（GPU／CPU）の確認と設定\n",
    "# GPUが利用可能か確認し、利用可能なら \"cuda\"、そうでなければ \"cpu\" をdeviceに設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# CNN_Attention_Modelのインスタンスを生成し、.to(device)で指定したデバイスにモデルを転送\n",
    "# モデルのパラメータ（重み）や計算が、指定したデバイスで実施されるようにする\n",
    "model = Attention_GRU_Model(vocab_size, embedding_dim, hidden_dim, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# 最適化手法と損失関数の定義\n",
    "# 最適化アルゴリズムとしてAdamを使用\n",
    "# model.parameters() を渡すことで、モデルが持つすべてのパラメータを最適化の対象として登録\n",
    "# lrは学習率（learning rate）で、パラメータ更新のステップ幅を決定\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 損失関数としてクロスエントロピー損失を定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# モデルの保存設定と学習ループの準備\n",
    "# 才能の検証損失を保存する変数を初期化することによって、検証データの損失が改善した場合にのみモデルを保存する\n",
    "# 早期終了（Early Stopping）に近い戦略\n",
    "best_valid_loss = np.inf\n",
    "MODEL_SAVE_PATH = PRJ_ROOT + 'improved_model_best_model.pth' # 最良モデルの保存先ファイルパス\n",
    "\n",
    "n_epoch = 10 # 学習エポック数\n",
    "for epoch in range(n_epoch):\n",
    "    # 各エポックの開始時に、訓練データと検証データの損失と正解数をリセット\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    accuracy_train = 0\n",
    "    accuracy_valid = 0\n",
    "\n",
    "    # 訓練モード\n",
    "    # model.train()を呼び出し、モデルを「訓練モード」に切り替える\n",
    "    # Dropout層やBatchNorm層などが訓練時の挙動となる\n",
    "    model.train()\n",
    "    for x,t in train_loader: # DataLoaderからミニバッチを1件ずつ取り出す\n",
    "        # データをモデルと同じデバイスに転送\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        # 前のバッチの勾配が累積しないように勾配をリセットする。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 順伝播\n",
    "        output = model(x)\n",
    "\n",
    "        # 損失計算：モデルの出力と正解ラベルとを比較し、損失を計算\n",
    "        loss = criterion(output, t)\n",
    "        # 逆伝播：損失に基づいて、各パラメータの勾配を計算\n",
    "        loss.backward()\n",
    "\n",
    "        # パラメータ更新：計算された勾配を基に、オプティマイザがモデルのパラメータを更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # 予測ラベルを計算。出力が最も大きいクラスを予測結果とするる\n",
    "        pred = output.argmax(dim=1)\n",
    "\n",
    "        # このバッチでの損失と正解数を、エポック全体の集計に加算\n",
    "        # .item()はテンソルからPythonのスカラー値を取り出す\n",
    "        loss_train += loss.item()\n",
    "        accuracy_train += torch.sum(pred == t.data)\n",
    "    \n",
    "    # 検証モード\n",
    "    # model.eval()を呼び出し、モデルを「検証モード」に切り替える\n",
    "    model.eval()\n",
    "\n",
    "    # 検証ではパラメータ更新はおこなわず、メモリ消費量を削減し、計算速度は向上する\n",
    "    with torch.no_grad():\n",
    "        for x,t in val_loader:\n",
    "            # データをデバイスに転送\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            # 順伝播\n",
    "            output = model(x)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(output, t)\n",
    "            \n",
    "            # 予測ラベルを計算\n",
    "            pred = output.argmax(dim=1)\n",
    "\n",
    "            # 損失と正解数を加算\n",
    "            loss_valid += loss.item()\n",
    "            # モデルの予測と正解ラベルとが等しいものの個数をカウントして足し合わせる\n",
    "            accuracy_valid += torch.sum(pred == t.data)\n",
    "    \n",
    "    # エポックごとの結果を計算して表示する\n",
    "    avg_loss_train = loss_train / len(train_loader)\n",
    "    avg_loss_valid = loss_valid / len(val_loader)\n",
    "    avg_acc_train = accuracy_train / len(train_dataset)\n",
    "    avg_acc_valid = accuracy_valid / len(val_dataset)\n",
    "\n",
    "    # 結果を整形して表示\n",
    "    print(\n",
    "        f\"| epoch {epoch+1:2d} | train loss {avg_loss_train:.4f}, acc {avg_acc_train:.4f} \"\n",
    "        f\"| valid loss {avg_loss_valid:.4f}, acc {avg_acc_valid:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 最良モデルの保存\n",
    "    # 検証データの損失が、これまでの最小値を更新した場合\n",
    "    if avg_loss_valid < best_valid_loss:\n",
    "        print(f\"Validation loss improved ({best_valid_loss:.4f} --> {avg_loss_valid:.4f}). Saving model...\")\n",
    "        best_valid_loss = avg_loss_valid # 最小損失を更新\n",
    "\n",
    "        # モデルのパラメータ（重み）のみを保存\n",
    "        torch.ave(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"\\nTraining finished. Best model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcdee2-9e48-4378-abf8-1e006c4ff0d0",
   "metadata": {},
   "source": [
    "### 改善モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fea85f-39fc-42af-80a7-d1b506a5e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価と結果の可視化\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\" '{PRJ_ROOT + 'improved_model_best_model.pth'}' を読み込んでいます...\")\n",
    "with open(PRJ_ROOT + 'improved_model_best_model.pth', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# pklファイル内のデータから、IDとカテゴリ名の対応辞書を再取得\n",
    "# 評価レポートやグラフのラベルとして使用\n",
    "id_to_label = data['id_to_label']\n",
    "\n",
    "# 評価レポート用に、カテゴリ名のリストもここから作成\n",
    "category_names = list(id_to_label.values())\n",
    "\n",
    "# 全ての予測結果と正解ラベルを格納するための空のリストを準備\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# モデルを「評価モード」に切り替える\n",
    "model.eval()\n",
    "\n",
    "#勾配計算を無効にして計算リソースを節約\n",
    "with torch.no_grad():\n",
    "    # テストデータ用のDataLoaderからミニバッチを１件ずつ取り出す\n",
    "    for x,t in test_loader:\n",
    "        # データをモデルと同じデバイにに転送\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "\n",
    "        # モデルにデータを入力し、順伝播させる\n",
    "        output = model(x)\n",
    "\n",
    "        # 最もスコアの高いクラスのインデックスを予測結果とする\n",
    "        pred = output.argmax(dim=1)\n",
    "\n",
    "        # 予測結果と正解ラベルをリストに追加\n",
    "        #　scikit-learnで計算するために、GPUのTensorからCPU上のリストに変換する\n",
    "        # .cpu()でCPUに転送し、.tolist()でPythonのリストに変換\n",
    "        # \n",
    "        all_preds.extend( pred.cpu().tolist() )\n",
    "        all_labels.extend( t.cpu().tolist() )\n",
    "        '''\n",
    "          当初は.numpy()でNumPy配列に変換しようとしていたが、RuntimeError: Numpy is not availableが発生した。\n",
    "          これは、NumPyライブラリが見つからない、または利用できない」ことを示している。\n",
    "          プリインストールされていたNumPyが他のライブラリとの兼ね合いなどで不安定になったと思われる。\n",
    "          ランタイムのリセット等を試したが、改善しなかったので、NumPyを一切経由せず、\n",
    "          Tensorを直接Pythonの標準的なリストに変換する .tolist() メソッドを使用した。\n",
    "          scikit-learnの評価関数はNumPy配列だけでなく、Pythonのリストも受け付けるため、この方法で問題なく動作。\n",
    "        ''' \n",
    "\n",
    "# 正解率（Accuracy）の計算\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 適合率（Precision）、再現率（Recall）、F1スコア（F1-Score）を含むレポートを表示\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(all_labels, all_preds, target_names=category_names)\n",
    "\n",
    "# 結果をテキストファイルに保存\n",
    "with open(DATA_DIR + \"Attention_GRU_test_results.txt\",\"w\") as f:\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# 混合行列（Confusion Matrix）の計算と可視化\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# numpy配列のままだと軸が数字で見づらいため、PandasのDataFrameに変換\n",
    "# indexとcolumnsにカテゴリ名を設定\n",
    "cm_df = pd.DataFrame(cm, index=category_names, columns=category_names)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10,8)) # グラフのサイズを指定\n",
    "# seabornのheatmap関数を使って、混合行列をヒートマップとして描画\n",
    "# annot=True：各セルに数値を表示\n",
    "# fmt='d': 数値を整数で表示\n",
    "# cmap='Greens': 色のテーマを指定\n",
    "sns.heatmap(cm_df, annot=True, cmap='Blues')\n",
    "plt.title('Confusion Matrix') # グラフのタイトル\n",
    "plt.ylabel('True Label') # Y軸のラベル\n",
    "plt.xlabel('Predicted Label') # X軸のラベル\n",
    "\n",
    "plt.tight_layout() # ラベルがグラフ領域からはみ出ないように自動調整\n",
    "\n",
    "# 混合行列を画像ファイルとして保存\n",
    "plt.savefig(PRJ_ROOT + \"Attention_GRU_confusion_matrix.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ac835-aad5-4603-b331-0ac68d6cc772",
   "metadata": {},
   "source": [
    "#### 改善モデルの予測結果の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd4330-e10f-4928-a6fe-9da81a48283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果をNumPyファイルとして保存\n",
    "np.save(PRJ_ROOT + 'attention_predictions.npy', np.array(all_preds))\n",
    "print(\"改善モデルの予測結果を attention_predictions.npy として保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f780bb-b205-4713-a6e6-5ef9acf35940",
   "metadata": {},
   "source": [
    "### 改善モデルの考察"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41985ab0-77d7-4726-b0ec-b958ef737c32",
   "metadata": {},
   "source": [
    "ベースラインモデルとの比較分析\n",
    "\n",
    "1. 全体の正解率（Accuracy）が大きく向上\n",
    "CNNモデル: 83.3%\n",
    "\n",
    "Attentionモデル: 89.0%\n",
    "\n",
    "正解率が約5.7%も向上しています。これは分類モデルの改善としては非常に大きな進歩です。\n",
    "\n",
    "2. 最大の弱点だったカテゴリが劇的に改善\n",
    "以前のモデルで最も苦手だった2つのカテゴリを見てみましょう。\n",
    "\n",
    "livedoor-homme\n",
    "\n",
    "CNNモデル (F1スコア): 0.50\n",
    "\n",
    "Attentionモデル (F1スコア): 0.65\n",
    "\n",
    "F1スコアが0.15ポイントも上昇しました。特に、モデルが見逃しがちだったことを示すrecallが 0.39 → 0.59 と大幅に改善しており、これまで見つけられなかった記事を正しく分類できるようになったことが分かります。\n",
    "\n",
    "peachy\n",
    "\n",
    "CNNモデル (F1スコア): 0.68\n",
    "\n",
    "Attentionモデル (F1スコア): 0.77\n",
    "\n",
    "こちらもF1スコアが0.09ポイント上昇し、顕著な改善が見られます。\n",
    "\n",
    "この結果から、Self-Attentionが、文全体の文脈や単語間の複雑な関係性を捉えることで、テーマが広範なカテゴリの分類精度を向上させたと強く推測できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be05a525-44d9-4ee1-b54e-17cbfc9353ac",
   "metadata": {},
   "source": [
    "## 考察と今後の課題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f77c2d-dea5-4493-bbc0-225b2b55cd07",
   "metadata": {},
   "source": [
    "### 考察"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bc589-ecd7-42d1-8219-6d10e7ca4d8b",
   "metadata": {},
   "source": [
    "#### ベースラインモデル／改善モデルの予測結果サンプルを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496727b-4ca9-4cf3-b342-a061fb4e4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存した両モデルの予測結果をロード\n",
    "cnn_preds = np.load(PRJ_ROOT + 'cnn_predictions.npy').tolist()\n",
    "attention_preds = np.load(PRJ_ROOT + 'attention_predictions.npy').tolist()\n",
    "\n",
    "# pklファイルから前処理済みデータと辞書をロード\n",
    "with open(DATA_DIR + 'processed_data_maxlen512.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "id_to_label = data['id_to_label']\n",
    "\n",
    "# テストデータの「原文」と「正解ラベル」を再取得\n",
    "from sklearn.model_selection import train_test_split\n",
    "raw_df = pd.read_csv(PRJ_ROOT + 'livedoor_news_corpus.csv') # 元の生データCSV\n",
    "\n",
    "# livedoor_news_corpus.csv テキストとラベルを取得\n",
    "X_raw = raw_df['text']\n",
    "y_raw = raw_df['label'].map( { label: i for i, label in enumerate(raw_df['label'].unique()) } ) # ラベルを数値化\n",
    "\n",
    "# 分割してテストデータを取得\n",
    "_, X_test_raw, _, test_labels = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.1, random_state=42, stratify=y_raw\n",
    ")\n",
    "\n",
    "test_texts = X_test_raw.tolist()\n",
    "\n",
    "# テストデータの原文、正解ラベル、両モデルの予測結果をまとめたDataFrameを作成\n",
    "results_df = pd.DataFrame({\n",
    "    'text': test_texts,\n",
    "    'true_label': test_labels,\n",
    "    'cnn_pred': cnn_preds,\n",
    "    'attention_pred': attention_preds\n",
    "})\n",
    "\n",
    "# IDをカテゴリ名に変換\n",
    "results_df['true_label_name'] = results_df['true_label'].map(id_to_label)\n",
    "results_df['cnn_pred_name'] = results_df['cnn_pred'].map(id_to_label)\n",
    "results_df['attention_pred_name'] = results_df['attention_pred'].map(id_to_label)\n",
    "\n",
    "# 抽出条件\n",
    "# ベースラインモデルでは誤分類したが、改善モデルでは正しく分類したもの\n",
    "condition1 = results_df['cnn_pred'] != results_df['true_label']\n",
    "condition2 = results_df['attention_pred'] == results_df['true_label']\n",
    "\n",
    "improved_examples = results_df[condition1 & condition2]\n",
    "\n",
    "# 結果の表示\n",
    "print(\"【改善事例の抽出結果】\")\n",
    "\n",
    "# 特に 'livedoor-homme' の事例を見てみる\n",
    "homme_improved = improved_examples[improved_examples['true_label_name'] == 'livedoor-homme']\n",
    "\n",
    "for index, row in homme_improved.head(3).iterrows():\n",
    "    print(\"=\"*50)\n",
    "    print(f\"【改善事例】 正解カテゴリ: {row['true_label_name']}\")\n",
    "    print(f\"  - CNNの予測 (間違い): {row['cnn_pred_name']}\")\n",
    "    print(f\"  - Attentionの予測 (正解): {row['attention_pred_name']}\")\n",
    "    print(\"\\n【記事本文 (冒頭部分)】\")\n",
    "    print(row['text'][:200] + \"...\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7ede9-4660-4349-9e3b-d940c563af6b",
   "metadata": {},
   "source": [
    "エラー分析: 実際にモデルが間違えた記事をいくつか読んでみて、なぜ間違えたのかを人間が分析することで、新たな改善のヒントが見つかることがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd16a78-908e-4a70-9863-6a46fe33b682",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8242a810-daa5-46cc-8857-36c5eb892960",
   "metadata": {},
   "source": [
    "### 今後の課題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def037fc-4103-40ca-8a05-16a0938b7df7",
   "metadata": {},
   "source": [
    "### 参考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfabf86-1b23-45f2-bc10-a9d3a3e76c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
